Directories: ['/data_noise_a', '/data_noise_b']
Loading local directories: ['/data_noise_a', '/data_noise_b']
Concat directories:
['/data_noise_a', '/data_noise_b']
Train size: 600 | Train shape: torch.Size([2, 256, 256])
Validation size: 200 | Validation shape: torch.Size([2, 256, 256])
Test size: 200 | Test shape: torch.Size([2, 256, 256])
Training  with validation split
Using device: cuda
Test only size: 299 | Test shape: torch.Size([2, 256, 256])
Directories: ['/data_noise_a', '/data_noise_b']
Loading local directories: ['/data_noise_a', '/data_noise_b']
Concat directories:
['/data_noise_a', '/data_noise_b']
Train size: 600 | Train shape: torch.Size([2, 256, 256])
Validation size: 200 | Validation shape: torch.Size([2, 256, 256])
Test size: 200 | Test shape: torch.Size([2, 256, 256])
Training  with validation split
Using device: cuda
Test only size: 299 | Test shape: torch.Size([2, 256, 256])
Directories: ['/data_noise_a', '/data_noise_b']
Loading local directories: ['/data_noise_a', '/data_noise_b']
Concat directories:
['/data_noise_a', '/data_noise_b']
Train size: 600 | Train shape: torch.Size([2, 256, 256])
Validation size: 200 | Validation shape: torch.Size([2, 256, 256])
Test size: 200 | Test shape: torch.Size([2, 256, 256])
Training  with validation split
Using device: cuda
Test only size: 299 | Test shape: torch.Size([2, 256, 256])
Directories: ['/data_noise_a', '/data_noise_b']
Loading local directories: ['/data_noise_a', '/data_noise_b']
Concat directories:
['/data_noise_a', '/data_noise_b']
Train size: 600 | Train shape: torch.Size([2, 256, 256])
Validation size: 200 | Validation shape: torch.Size([2, 256, 256])
Test size: 200 | Test shape: torch.Size([2, 256, 256])
Training  with validation split
Using device: cuda
Test only size: 299 | Test shape: torch.Size([2, 256, 256])
Directories: ['/data_noise_a', '/data_noise_b']
Loading local directories: ['/data_noise_a', '/data_noise_b']
Concat directories:
['/data_noise_a', '/data_noise_b']
Train size: 600 | Train shape: torch.Size([2, 256, 256])
Validation size: 200 | Validation shape: torch.Size([2, 256, 256])
Test size: 200 | Test shape: torch.Size([2, 256, 256])
Training  with validation split
Loading local directories: ['/data_noise_b']
Concat directories:
['/data_noise_b']
Train size: 300 | Train shape: torch.Size([2, 256, 256])
Validation size: 100 | Validation shape: torch.Size([2, 256, 256])
Test size: 100 | Test shape: torch.Size([2, 256, 256])
Using device: cuda
Test only size: 299 | Test shape: torch.Size([2, 256, 256])
Directories: ['/data_noise_a', '/data_noise_b']
Loading local directories: ['/data_noise_a', '/data_noise_b']
Concat directories:
['/data_noise_a', '/data_noise_b']
Train size: 600 | Train shape: torch.Size([2, 256, 256])
Validation size: 200 | Validation shape: torch.Size([2, 256, 256])
Test size: 200 | Test shape: torch.Size([2, 256, 256])
Training  with validation split
Using device: cuda
Test only size: 299 | Test shape: torch.Size([2, 256, 256])
Directories: ['/data_noise_a', '/data_noise_b']
Loading local directories: ['/data_noise_a', '/data_noise_b']
Concat directories:
['/data_noise_a', '/data_noise_b']
Train size: 600 | Train shape: torch.Size([2, 256, 256])
Validation size: 200 | Validation shape: torch.Size([2, 256, 256])
Test size: 200 | Test shape: torch.Size([2, 256, 256])
Training  with validation split
wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.
Using device: cuda
Test only size: 299 | Test shape: torch.Size([2, 256, 256])
Directories: ['/data_noise_a', '/data_noise_b']
Loading local directories: ['/data_noise_a', '/data_noise_b']
Concat directories:
['/data_noise_a', '/data_noise_b']
Train size: 600 | Train shape: torch.Size([2, 256, 256])
Validation size: 200 | Validation shape: torch.Size([2, 256, 256])
Test size: 200 | Test shape: torch.Size([2, 256, 256])
Training  with validation split
